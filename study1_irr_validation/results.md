# IRR Validation Results

The inter-rater reliability analysis yielded strong results, confirming that the perturbation coding scheme is robust and reliable. The final agreement scores between the human expert and the LLM coder were as follows:

| Metric | Value | Interpretation |
| :--- | :--- | :--- |
| **Cohen's Kappa (Îº)** | **0.821** | Almost Perfect Agreement |
| **Raw Agreement (All Seconds)** | **96.4%** | High level of direct agreement |
| **Agreement on Perturbations** | **84.1%** | Strong agreement on positive cases of perturbation markings |
| **Statistical Significance** | **p < .001** | Agreement is not due to chance |

These results provide strong evidence that the LLM is a reliable second coder for this task, and the resulting dataset is robust for the main study's analyses.
